{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1824f39-52d7-4581-a076-ae10f6b5812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91bca24-6c0c-43c3-bcaf-798d482cd6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "sonar_data = pd.read_csv('C:/Users/ADMIN/Downloads/sonar_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781aaaec-aa9b-4659-a572-43bb601399d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0       1       2       3       4       5       6       7       8   \\\n",
      "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
      "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
      "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
      "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
      "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
      "\n",
      "       9   ...      51      52      53      54      55      56      57  \\\n",
      "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
      "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
      "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
      "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
      "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
      "\n",
      "       58      59  60  \n",
      "0  0.0090  0.0032   R  \n",
      "1  0.0052  0.0044   R  \n",
      "2  0.0095  0.0078   R  \n",
      "3  0.0040  0.0117   R  \n",
      "4  0.0107  0.0094   R  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows\n",
    "print(sonar_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae27ebee-d004-4604-880c-d7bdd1da172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (208, 61)\n"
     ]
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "print(f\"Dataset shape: {sonar_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a79baa-1320-4c4c-83be-a1b80b046341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0           1           2           3           4           5   \\\n",
      "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
      "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
      "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
      "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
      "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
      "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
      "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
      "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
      "\n",
      "               6           7           8           9   ...          50  \\\n",
      "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
      "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
      "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
      "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
      "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
      "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
      "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
      "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
      "\n",
      "               51          52          53          54          55          56  \\\n",
      "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
      "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
      "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
      "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
      "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
      "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
      "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
      "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
      "\n",
      "               57          58          59  \n",
      "count  208.000000  208.000000  208.000000  \n",
      "mean     0.007949    0.007941    0.006507  \n",
      "std      0.006470    0.006181    0.005031  \n",
      "min      0.000300    0.000100    0.000600  \n",
      "25%      0.003600    0.003675    0.003100  \n",
      "50%      0.005800    0.006400    0.005300  \n",
      "75%      0.010350    0.010325    0.008525  \n",
      "max      0.044000    0.036400    0.043900  \n",
      "\n",
      "[8 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Statistical measures of the data\n",
    "print(sonar_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696f57a0-a67a-4ac9-bde6-dc53eea524b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "M    111\n",
      "R     97\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the values of the target column\n",
    "print(sonar_data[60].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f7c98e2-7061-4549-b38e-eb5668645283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "60                                                                         \n",
      "M   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \n",
      "R   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n",
      "\n",
      "          7         8         9   ...        50        51        52        53  \\\n",
      "60                                ...                                           \n",
      "M   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \n",
      "R   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n",
      "\n",
      "          54        55        56        57        58        59  \n",
      "60                                                              \n",
      "M   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \n",
      "R   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n",
      "\n",
      "[2 rows x 60 columns]\n"
     ]
    }
   ],
   "source": [
    "# Grouping the data by the target column and finding the mean\n",
    "print(sonar_data.groupby(60).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dd93179-568a-482f-8179-b390ffd7e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data and labels\n",
    "X = sonar_data.drop(columns=60, axis=1)\n",
    "Y = sonar_data[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a82e1c5a-a8c0-4895-846c-57eb6523b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, stratify=Y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdebdef0-7dc1-4c41-b2c9-8d980c58503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef8adabc-98a3-437e-9f1f-9306ce9c0f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 5000, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the updated parameter grid with supported solvers for penalties\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],              # l1 is not supported for saga, so ensure compatible solvers\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga'],      # saga supports l2 and elasticnet\n",
    "    'max_iter': [5000],                   # Increase max_iter only if needed (start with a reasonable value)\n",
    "    'class_weight': ['balanced']          # Included in grid search in case you'd like to tune it\n",
    "}\n",
    "\n",
    "# GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),  # Add random_state for reproducibility\n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Display the best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e342541-0e00-4fde-ac6c-a9f8e0ac1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model\n",
    "best_logistic_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "481bd0f8-9bc2-49fa-bd60-2aab67b4fef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Training accuracy: 0.8824\n",
      "Logistic Regression - Test accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "# Training and test accuracy with tuned Logistic Regression model\n",
    "train_accuracy = best_logistic_model.score(X_train_scaled, Y_train)\n",
    "test_accuracy = best_logistic_model.score(X_test_scaled, Y_test)\n",
    "print(f\"Logistic Regression - Training accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Logistic Regression - Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8524646-dc2d-458d-833e-3129ee7eb275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Training accuracy: 1.0000\n",
      "Random Forest - Test accuracy: 0.7619\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Trying different models (Random Forest and SVM)\n",
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=1)\n",
    "rf_model.fit(X_train_scaled, Y_train)\n",
    "rf_train_accuracy = rf_model.score(X_train_scaled, Y_train)\n",
    "rf_test_accuracy = rf_model.score(X_test_scaled, Y_test)\n",
    "print(f\"Random Forest - Training accuracy: {rf_train_accuracy:.4f}\")\n",
    "print(f\"Random Forest - Test accuracy: {rf_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03e8f82f-5def-42fa-b84a-7a35e6e4a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM - Training accuracy: 0.9679\n",
      "SVM - Test accuracy: 0.9048\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "svm_model = SVC(class_weight='balanced', random_state=1)\n",
    "svm_model.fit(X_train_scaled, Y_train)\n",
    "svm_train_accuracy = svm_model.score(X_train_scaled, Y_train)\n",
    "svm_test_accuracy = svm_model.score(X_test_scaled, Y_test)\n",
    "print(f\"SVM - Training accuracy: {svm_train_accuracy:.4f}\")\n",
    "print(f\"SVM - Test accuracy: {svm_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5725e6d-998e-4589-9437-1f7099af6787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Cross-validation scores: [0.78947368 0.78947368 0.75675676 0.78378378 0.86486486]\n",
      "Average CV score: 0.7969\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Cross-validation for best Logistic Regression model\n",
    "cv_scores = cross_val_score(best_logistic_model, X_train_scaled, Y_train, cv=5)\n",
    "print(f\"Logistic Regression - Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Average CV score: {np.mean(cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6890de9e-7da4-4b13-a473-0e09f0fd0412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression - Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           M       0.73      0.73      0.73        11\n",
      "           R       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.71      0.71      0.71        21\n",
      "weighted avg       0.71      0.71      0.71        21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for Logistic Regression\n",
    "Y_test_pred = best_logistic_model.predict(X_test_scaled)\n",
    "print(\"\\nLogistic Regression - Classification Report:\")\n",
    "print(classification_report(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a13bd12-d052-4830-93bf-27d1906a5c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The object is a Mine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Making a prediction for a single input instance\n",
    "input_data = (0.0307, 0.0523, 0.0653, 0.0521, 0.0611, 0.0577, 0.0665, 0.0664, \n",
    "              0.1460, 0.2792, 0.3877, 0.4992, 0.4981, 0.4972, 0.5607, 0.7339, \n",
    "              0.8230, 0.9173, 0.9975, 0.9911, 0.8240, 0.6498, 0.5980, 0.4862, \n",
    "              0.3150, 0.1543, 0.0989, 0.0284, 0.1008, 0.2636, 0.2694, 0.2930, \n",
    "              0.2925, 0.3998, 0.3660, 0.3172, 0.4609, 0.4374, 0.1820, 0.3376, \n",
    "              0.6202, 0.4448, 0.1863, 0.1420, 0.0589, 0.0576, 0.0672, 0.0269, \n",
    "              0.0245, 0.0190, 0.0063, 0.0321, 0.0189, 0.0137, 0.0277, 0.0152, \n",
    "              0.0052, 0.0121, 0.0124, 0.0055)\n",
    "\n",
    "# Convert input data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# Reshape and scale the input data\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
    "input_data_scaled = scaler.transform(input_data_reshaped)\n",
    "\n",
    "# Make a prediction using the best Logistic Regression model\n",
    "prediction = best_logistic_model.predict(input_data_scaled)\n",
    "\n",
    "# Display prediction result\n",
    "if prediction[0] == 'R':\n",
    "    print('The object is a Rock')\n",
    "else:\n",
    "    print('The object is a Mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "beb9f9fa-a8c5-426a-aacb-e9cdecbd0984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_svm_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(svm_model, 'best_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac563611-ba30-4fd2-aa48-a5e9b4f76cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.pkl')  # Save the scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204451f-be25-4bd9-81e6-418cc17f4e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
